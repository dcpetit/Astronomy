{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpCQQOVDpJFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31774c6-5277-467c-99cd-48859ea3503c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtDA40LsrBT0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "227723f5-480f-43d7-ea6a-8170b14faad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/PynPoint\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astropy~=5.0.0 (from pynpoint==0.10.0)\n",
            "  Downloading astropy-5.0.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emcee~=3.1.0 (from pynpoint==0.10.0)\n",
            "  Downloading emcee-3.1.4-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py~=3.6.0 (from pynpoint==0.10.0)\n",
            "  Downloading h5py-3.6.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba~=0.55.0 (from pynpoint==0.10.0)\n",
            "  Downloading numba-0.55.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy~=1.22.0 (from pynpoint==0.10.0)\n",
            "  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python~=4.5.0 (from pynpoint==0.10.0)\n",
            "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting photutils~=1.4.0 (from pynpoint==0.10.0)\n",
            "  Downloading photutils-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.1/829.1 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyWavelets~=1.3.0 (from pynpoint==0.10.0)\n",
            "  Downloading PyWavelets-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image~=0.19.0 in /usr/local/lib/python3.10/dist-packages (from pynpoint==0.10.0) (0.19.3)\n",
            "Collecting scikit-learn~=1.0.0 (from pynpoint==0.10.0)\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy~=1.8.0 (from pynpoint==0.10.0)\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting statsmodels~=0.13.0 (from pynpoint==0.10.0)\n",
            "  Downloading statsmodels-0.13.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm~=4.64.0 (from pynpoint==0.10.0)\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard~=2.13.0 (from pynpoint==0.10.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyerfa>=2.0 in /usr/local/lib/python3.10/dist-packages (from astropy~=5.0.0->pynpoint==0.10.0) (2.0.0.3)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from astropy~=5.0.0->pynpoint==0.10.0) (6.0.1)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from astropy~=5.0.0->pynpoint==0.10.0) (23.1)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1 (from numba~=0.55.0->pynpoint==0.10.0)\n",
            "  Downloading llvmlite-0.38.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba~=0.55.0->pynpoint==0.10.0) (67.7.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image~=0.19.0->pynpoint==0.10.0) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image~=0.19.0->pynpoint==0.10.0) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image~=0.19.0->pynpoint==0.10.0) (2.31.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image~=0.19.0->pynpoint==0.10.0) (2023.9.26)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn~=1.0.0->pynpoint==0.10.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn~=1.0.0->pynpoint==0.10.0) (3.2.0)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from statsmodels~=0.13.0->pynpoint==0.10.0) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels~=0.13.0->pynpoint==0.10.0) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->statsmodels~=0.13.0->pynpoint==0.10.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->statsmodels~=0.13.0->pynpoint==0.10.0) (2023.3.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels~=0.13.0->pynpoint==0.10.0) (1.16.0)\n",
            "Building wheels for collected packages: pynpoint\n",
            "  Building wheel for pynpoint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynpoint: filename=pynpoint-0.10.0-py3-none-any.whl size=200945 sha256=d4ed32e877d3f0486bf101717251abec8b6b5c395a6db61f70b5c8c7a5d9dbd7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ycargqsj/wheels/66/ad/29/e5c2b1a8debdaa7e0d584b44d5634e51cbafd0b3e884ee3ccc\n",
            "Successfully built pynpoint\n",
            "Installing collected packages: typeguard, tqdm, numpy, llvmlite, scipy, PyWavelets, opencv-python, numba, h5py, emcee, statsmodels, scikit-learn, astropy, photutils, pynpoint\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.3\n",
            "    Uninstalling scipy-1.11.3:\n",
            "      Successfully uninstalled scipy-1.11.3\n",
            "  Attempting uninstall: PyWavelets\n",
            "    Found existing installation: PyWavelets 1.4.1\n",
            "    Uninstalling PyWavelets-1.4.1:\n",
            "      Successfully uninstalled PyWavelets-1.4.1\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.14.0\n",
            "    Uninstalling statsmodels-0.14.0:\n",
            "      Successfully uninstalled statsmodels-0.14.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: astropy\n",
            "    Found existing installation: astropy 5.3.3\n",
            "    Uninstalling astropy-5.3.3:\n",
            "      Successfully uninstalled astropy-5.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.12.3 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.12.3 requires statsmodels>=0.14.0, but you have statsmodels 0.13.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyWavelets-1.3.0 astropy-5.0.8 emcee-3.1.4 h5py-3.6.0 llvmlite-0.38.1 numba-0.55.2 numpy-1.22.4 opencv-python-4.5.5.64 photutils-1.4.0 pynpoint-0.10.0 scikit-learn-1.0.2 scipy-1.8.1 statsmodels-0.13.5 tqdm-4.64.1 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6f173698cd74>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#matplotlib.use('Agg') #writes results to file, not post in a window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install /content/drive/MyDrive/PynPoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpynpoint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pynpoint/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpynpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpypeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPypeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpynpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackground\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleBackgroundSubtractionModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                                            \u001b[0mMeanBackgroundSubtractionModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                            \u001b[0mLineSubtractionModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pynpoint/processing/background.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpynpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpynpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpynpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_func\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubtract_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pynpoint/util/apply_func.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mphotutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maperture_photometry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mphotutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maperture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAperture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0m_ensure_llvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m \u001b[0m_ensure_critical_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;31m# we know llvmlite is working as the above tests passed, import it now as SVML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/__init__.py\u001b[0m in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Numba needs NumPy 1.18 or greater\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnumpy_version\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Numba needs NumPy 1.22 or less\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 1.22 or less",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, \"../../Programm/PynPoint\")\n",
        "sys.path.insert(0, \"../../Programm/PynGit/species\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "#matplotlib.use('Agg') #writes results to file, not post in a window\n",
        "!pip install /content/drive/MyDrive/PynPoint\n",
        "import pynpoint as pp\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------- variables\n",
        "# user defined variables\n",
        "iwa = 10               # inner working angle                \t(default = 10)\n",
        "im_extra_rot = 0       # additional rotation offset         \t(default = 0)\n",
        "im_size_fc_crop  = 200 # Cropping size after data reduction \t(default = 200)\n",
        "im_size_pca_crop = 200 # Cropping size after pca analysis   \t(default = 200)\n",
        "\n",
        "# fix variables\n",
        "pixscale = 0.00746     # (FIX) pixel to arcsec scale\t\t    (initially = 0.00746)\n",
        "ce_r_min = 47          # (FIX) minimum radius of waffle spots\t(initially = 47)\n",
        "ce_l_min = 0.953       # (FIX) smallest observed wavelength\t    (initially = 0.953)\n",
        "\n",
        "\n",
        "\n",
        "# PynPoint SetUp\n",
        "path_working = '/content/drive/MyDrive/working' #'./working'\n",
        "path_in      = '/content/drive/MyDrive/reduced' #'./reduced'\n",
        "path_out     = '/content/drive/MyDrive/results' #'./results'\n",
        "\n",
        "path_in_data = '/content/drive/MyDrive/reduced' #'./reduced'\n",
        "path_in_wave = '/content/drive/MyDrive/reduced/wave/wavelength.fits' #'../../thesis_publication/wave/wavelength.fits'\n",
        "path_in_angl = '/content/drive/MyDrive/reduced/angles/angles.fits' # '../../thesis_publication/angles/angles.fits'\n",
        "\n",
        "# ---------------------------------------------------------------------- pre run checks\n",
        "\n",
        "# Add the psf directory to PynPoint SetUp - copy it into the MyDrive directory (like above)\n",
        "psf = '/content/drive/MyDrive/psf/' #  './psf/' #This is probably useless\n",
        "input_dir = 'psf'\n",
        "\n",
        "# check input directory\n",
        "print(path_in)\n",
        "assert os.path.isdir(path_in), 'Input directory not valid'\n",
        "\n",
        "# Create Working directory for this target\n",
        "if not os.path.isdir(path_working):\n",
        "    print(\"Creating directory: %s\" % (path_working))\n",
        "    os.makedirs(path_working)\n",
        "\n",
        "# Create directory for results\n",
        "if not os.path.isdir(path_out):\n",
        "    print(\"Creating directory: %s\" % (path_out))\n",
        "\n",
        "# ---------------------------------------------------------------------- Pypelin set up\n",
        "\n",
        "# Set up the Pypelin\n",
        "pipeline = pp.Pypeline(working_place_in = path_working,\n",
        "                       input_place_in   = path_in,\n",
        "                       output_place_in  = path_out)\n",
        "\n",
        "# --- read in of science frame and wavelength/angle of the frames\n",
        "im_reading_mod = pp.FitsReadingModule(name_in=\"im_reading_mod\",\n",
        "                                      input_dir=path_in_data,\n",
        "                                      image_tag=\"im\",\n",
        "                                      ifs_data=True)\n",
        "\n",
        "\n",
        "#FPI\n",
        "psf_reading_mod = pp.FitsReadingModule(name_in='psf_read',\n",
        "                                       input_dir=psf, #'psf'\n",
        "                                       image_tag='psf_test',\n",
        "                                       ifs_data=True)\n",
        "\n",
        "\n",
        "im_wavel_mod = pp.WavelengthReadingModule(name_in = \"im_wavel_read\",\n",
        "                                          data_tag = \"im\",\n",
        "                                          file_name = path_in_wave)\n",
        "\n",
        "im_angle_mod = pp.ParangReadingModule(name_in = \"im_angle_read\",\n",
        "                                      data_tag = \"im\",\n",
        "                                      file_name = path_in_angl)\n",
        "\n",
        "\n",
        "\n",
        "# --- additional preprocessing\n",
        "im_sort_parang = pp.SortParangModule(name_in = \"sort_parang\",\n",
        "                                     image_in_tag = \"im\",\n",
        "                                     image_out_tag = \"im_sorted\")\n",
        "\n",
        "\n",
        "# --- intermediat printing to check data\n",
        "im_stack = pp.DerotateAndStackModule(name_in = \"im_stack_dict\",\n",
        "                                         image_in_tag = 'im',\n",
        "                                         image_out_tag = 'im_stack',\n",
        "                                         derotate = True,\n",
        "                                         stack = 'median',\n",
        "                                         extra_rot = 0,\n",
        "                                         dimension = 'wavelength')\n",
        "\n",
        "im_stack_write = pp.FitsWritingModule(name_in = \"im_stack_write\",\n",
        "                                     file_name= \"im_stack.fits\",\n",
        "                                     data_tag = \"im_stack\")\n",
        "\n",
        "\n",
        "\n",
        "# --- preparation of the data\n",
        "im_prep_mod = pp.PSFpreparationModule(name_in = \"the_real_preparation_mod\",\n",
        "                                      image_in_tag = \"im\",\n",
        "                                      image_out_tag = \"im_pca_prep\",\n",
        "                                      mask_out_tag = \"mask_sdi_prep\",\n",
        "                                      norm=False,\n",
        "                                      resize=None,\n",
        "                                      cent_size=iwa*pixscale,\n",
        "                                      edge_size=im_size_pca_crop*pixscale)\n",
        "\n",
        "\n",
        "im_prep_write = pp.FitsWritingModule(name_in = \"im_pca_prep\",\n",
        "                                     file_name= \"im_pca_prep.fits\",\n",
        "                                     data_tag = \"im_pca_prep\")\n",
        "\n",
        "\n",
        "# FPI!\n",
        "fake_test = pp.FakePlanetModule(name_in = 'fake_test',\n",
        "                                image_in_tag = \"im_pca_prep\",\n",
        "                                psf_in_tag = \"psf_test\",\n",
        "                                image_out_tag = \"im_fake_test\",\n",
        "                                position = (-1.15, 0),\n",
        "                                magnitude = np.asarray(np.multiply([-1.0, -1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "                                                        \t-1.0, -1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "                                                        \t-1.0, -1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "                                                        \t-1.0, -1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "                                                        \t-1.0, -1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "                                                        \t-1.0, -1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "                                                        \t-1.0, -1.0, -1.0], 5) ),\n",
        "                                #magnitude = np.asarray([9., -8., 9., 0., 9., 0.,\n",
        "                                #                        9., 0., 9., 0., 9., 0.,\n",
        "                                #                        9., 0., 9., 0., 9., 0.,\n",
        "                                #                        9., 0., 9., 0., 9., 0.,\n",
        "                                #                        9., 0., 9., 0., 9., 0.,\n",
        "                                # The Original           9., 0., 9., 0., 9., 0.,\n",
        "                                #                        9., 0., 9.]),\n",
        "                                psf_scaling = 1.,\n",
        "                                interpolation = 'spline')\n",
        "\n",
        "\n",
        "fake_write = pp.FitsWritingModule(name_in = \"fake_write\",\n",
        "                                  file_name = \"fake_test.fits\",\n",
        "                                  data_tag = \"im_fake_test\")\n",
        "\n",
        "print('Finished assigning fake_write, define evaluate and go to the next cell')\n",
        "\n",
        "def evaluate(pipe, p_t, pca):\t\t# for example: evaluate(pipeline, 'ADI',  ([1,2,3]))\n",
        "\n",
        "\n",
        "    # --- Perform pca reduction\n",
        "    the_real_test_mod = pp.PcaPsfSubtractionModule(name_in = p_t + '_wave_test_mod',\n",
        "                                                          images_in_tag = 'im_fake_test',\n",
        "                                                          reference_in_tag = 'im_pca_prep',\n",
        "                                                          res_mean_tag = p_t + '_wave_mean',\n",
        "                                                          res_median_tag = p_t + '_wave_median',\n",
        "                                                          res_weighted_tag = None,\n",
        "                                                          res_rot_mean_clip_tag = None,\n",
        "                                                          res_arr_out_tag  = None,\n",
        "                                                          basis_out_tag  = None,\n",
        "                                                          pca_numbers = pca,\n",
        "                                                          extra_rot = im_extra_rot,\n",
        "                                                          subtract_mean = True, # makes the image background average at 0\n",
        "                                                          processing_type = p_t)\n",
        "\n",
        "\n",
        "\n",
        "    # --- write PCA results\n",
        "    the_real_median_write_mod = pp.FitsWritingModule(name_in = p_t + \"_wave_median_write_mod\",\n",
        "                                                     file_name= p_t + \"_wave_median.fits\",\n",
        "                                                     data_tag = p_t + \"_wave_median\")\n",
        "\n",
        "\n",
        "    the_real_mean_write_mod = pp.FitsWritingModule(name_in = p_t + \"_wave_mean_write_mod\",\n",
        "                                                   file_name = p_t + \"_wave_mean.fits\",\n",
        "                                                   data_tag = p_t + \"_wave_mean\")\n",
        "\n",
        "\n",
        "\n",
        "    #add all modules\n",
        "    pipe.add_module(the_real_test_mod)\n",
        "    pipe.add_module(the_real_median_write_mod)\n",
        "    pipe.add_module(the_real_mean_write_mod)\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------ Pypelin set execution\n",
        "\n",
        "pipeline.add_module(im_reading_mod)\n",
        "pipeline.add_module(im_wavel_mod)\n",
        "pipeline.add_module(im_angle_mod)\n",
        "pipeline.add_module(im_sort_parang) #vestigual\n",
        "pipeline.add_module(im_stack)\n",
        "pipeline.add_module(im_stack_write)\n",
        "pipeline.add_module(im_prep_mod)\n",
        "pipeline.add_module(im_prep_write)\n",
        "\n",
        "# FPI's\n",
        "pipeline.add_module(psf_reading_mod)\n",
        "pipeline.add_module(fake_test)\n",
        "pipeline.add_module(fake_write)\n",
        "\n",
        "#The Real #Reel?\n",
        "#evaluate(pipeline, 'SDI',  ([1,2,3,4]))\t\t\t\t#(initially = [1,2])\n",
        "evaluate(pipeline, 'SDI+ADI', ([1], [1]))\t#(initially = ([1,2,3,4,5], [1,2,3,4,5])\n",
        "#evaluate(pipeline, 'ADI+SDI', ([1,2,3], [1,2,3]))\t#(initially = ([1,2,3,4,5], [1,2,3,4,5]) and un-commented\n",
        "#evaluate(pipeline, 'CODI', ([40]))\t\t#(initially = ([100,200,300,400]))\n",
        "\n",
        "\n",
        "# run the pipeline\n",
        "pipeline.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y9AGyhVrlhv"
      },
      "outputs": [],
      "source": [
        "# Get the data as an image from a fits *FILE* (the above reduction)\n",
        "\n",
        "from astropy.io import fits\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt #matplotlib.use('Agg')\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "path = '/content/drive/MyDrive/' # SADI_wave_median_PCA=1-10_Mag=-1,7_Pos=-1,15.fits #path = '/home/dcpetit/Documents/kuleuven_astronomy/thesis_publication/results/'\n",
        "#image_file_FPI = path+'SADI_wave_median_PCA=1-10_Mag=-1,7_Pos=-1,15.fits'\n",
        "image_file_FPI = path+'/results/SDI+ADI_wave_median.fits'\n",
        "image_data_FPI = fits.getdata(image_file_FPI, ext=0)\n",
        "print('np.shape(image_data_FPI):', np.shape(image_data_FPI))\n",
        "x, y = image_data_FPI[0][0][0], image_data_FPI[0][0][1]\n",
        "\n",
        "# Fucntions to get signal data, given the PCAs and wavelength channel\n",
        "\n",
        "def set_signalMatrix_1_WLC_1_PCA(image_data, x, y, PCA, WL):\n",
        "    signal_matrix = np.zeros(200*200).reshape(200,200)\n",
        "    for i in range(len(x)):\n",
        "        for j in range(len(y)):\n",
        "            signal_matrix[i][j] = image_data[PCA][WL][i][j]\n",
        "    return(signal_matrix)\n",
        "\n",
        "def set_signalMatrix_1_WLC_2_PCA(image_data, x, y, PCA1, PCA2, WL):\n",
        "    signal_matrix = np.zeros(200*200).reshape(200,200)\n",
        "    for i in range(len(x)):\n",
        "        for j in range(len(y)):\n",
        "            signal_matrix[i][j] = image_data[PCA1-1][PCA2-1][WL][i][j] # This selects the 33rd Wavelength Detector for ASDI/SADI data with PCA1 = PCA2 = 0\n",
        "    return(signal_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWnXwky5_fNR"
      },
      "outputs": [],
      "source": [
        "# Determine the location of the exact injected FPI (that gets smeared around)\n",
        "\n",
        "sep_arcsec = -1.15  # Separation (arcsec)\n",
        "pixScale = 0.00746  # pixels * arcsec/pixels = arcsec\n",
        "sep_pixel = -1.15/pixScale\n",
        "possible_FPI_pixel = [100, -(sep_pixel+100)]\n",
        "print(sep_pixel)\n",
        "print(possible_FPI_pixel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKc6u0KfTddT"
      },
      "outputs": [],
      "source": [
        "# Define the CB Parameters... Use the circle from SNR calculations, turn it into a square...\n",
        "diameter = 5;                    D = diameter\n",
        "radius = int(diameter/2);        R = radius\n",
        "location_demo = (80, 131);       L_demo = location_demo\n",
        "location = (80, 103);            L = location\n",
        "separation = 50;                 S = separation\n",
        "decay_factor = 0.9;              DF= decay_factor\n",
        "angular_squares, radial_squares = 4, 4 # I think there's no code that uses this now - 5 July 23\n",
        "x_squares, y_squares = 4, 3   # switch for imshow\n",
        "center_square = [2, 4]\n",
        "max_brightness, MB = 10, 10   # half_edge = np.sqrt(radius**2 + separation**2) - separation + radius\n",
        "amp_nonRad_less = 2           # Earlier idea: Use a 2nd Maximum Brightnesses... One for SDI/radial CB spaces... One for all other CB spaces\n",
        "\n",
        "#amplitude_radial_boost = 2    # Use a 2nd Maximum Brightnesses... One for SDI/radial CB spaces... One for all other CB spaces\n",
        "#amp_radial_boost = 2          # Make a radial and non-radial, augmentation and diminishing factor\n",
        "#angular_squares, radial_squares = 4, 4 # I think there's no code that uses this now - 5 July 23\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuAPo9hyTVl-"
      },
      "outputs": [],
      "source": [
        "# Define a fucntion for a checkerboard with no hole for the preseumed exoplanet (just a designated square for the exoplanet)\n",
        "def make_oscillating_checkerboard_noGap(diameter, x, y, center_square, amplitude, amp_nonRad_less, location, delay_x, delay_y, decay_factor): # amp_radial_boost,\n",
        "    checkerboard4D = np.zeros([x, y, diameter, diameter])\n",
        "    checkerboard = np.zeros([200, 200])\n",
        "    for i in range(x):                          #each row of squares\n",
        "        for j in range(y):                      #each column of squares\n",
        "            displacement_square = [ i - (center_square[1]-1) , j - (center_square[0]-1) ] # center_square[index] is backwards for IMSHOW\n",
        "            decay_exponent = (np.sqrt(displacement_square[0]**2 + displacement_square[1]**2))\n",
        "            if displacement_square[1] == 0:\n",
        "                adjustment = 1 #amp_radial_boost\n",
        "            else:\n",
        "                adjustment = amp_nonRad_less**(-1)\n",
        "            if np.sum(displacement_square) % 2 != 0:\n",
        "                N = 1 * adjustment * decay_factor**decay_exponent   #if displacement_square[0] == 0 and displacement_square[1] == 0:  N = 0   el\n",
        "            elif np.sum(displacement_square) % 2 == 0:\n",
        "                N = -1 * adjustment * decay_factor**decay_exponent\n",
        "            else:\n",
        "                print('problem in checkerboard creation')\n",
        "            for k in range(diameter):                  #each x pixel\n",
        "                for l in range(diameter):              #each y pixel\n",
        "                    checkerboard4D[i, j, k, l] = N * amplitude * np.cos(np.pi * k / diameter - delay_y) * np.cos(np.pi * l / diameter - delay_x) # it's an l, not a 1 ... #this one is a sine function, could test it out with a gaussian function\n",
        "            L0, L1 = location[0], location[1]\n",
        "            checkerboard[i*diameter+L0:(i+1)*diameter+L0, j*diameter+L1:(j+1)*diameter+L1] = checkerboard4D[i,j,:,:]\n",
        "    return checkerboard, checkerboard4D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L99VQbSET5hE"
      },
      "outputs": [],
      "source": [
        "# Make the same plots as above, but use the wavy checkerboard instead...\n",
        "def add_wavy_checkerboard(observation, checkerboard):\n",
        "    merged_observation_WavyCheckerboard = np.add(observation, checkerboard)\n",
        "    return merged_observation_WavyCheckerboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the wavelength channel (bin) ranges, and then use their distances to calculate a how much of a phase change should be between each channel\n",
        "wavelength_channels = [ 954.32282227,  962.62163342,  971.8455533, 981.89907773,  991.62082995, 1001.70638262,\n",
        "                        1012.66201578, 1023.29215927, 1033.63748036, 1043.90899136, 1054.17332605, 1064.93904728,\n",
        "                        1075.51906673, 1085.48399237, 1095.372864, 1105.07626751, 1115.18984928, 1127.09242581,\n",
        "                        1138.79673007, 1149.43864103, 1159.42615783, 1169.31067405, 1179.38222723, 1189.4464981,\n",
        "                        1199.5333784, 1209.88668205, 1220.04015567, 1229.96503806, 1240.57338913, 1250.6362063,\n",
        "                        1260.9653672,  1271.4195118,  1281.94965148,1291.7051642,  1300.62445043, 1309.61923874,\n",
        "                        1318.81874937, 1327.10100597, 1333.64664519] # This comes from the output of psfsubtraction.py which is seen in the reduction cell\n",
        "#plt.plot(wavelength_channels, 'o')\n",
        "print(\"np.shape(wavelength_channels)\", np.shape(wavelength_channels))\n",
        "print(wavelength_channels)\n",
        "# Given a range (1.5*pi radians), make a descrete sign function that is evaluated in the spacing that the wavelength channels are distributed\n",
        "wlMin, wlMax, wlDistribution = np.min(wavelength_channels), np.max(wavelength_channels), []\n",
        "for i in wavelength_channels:\n",
        "    wlDistribution.append(10*(wlMax - i)/(wlMax - wlMin) - 7.6) # This will replace 39 WLCs with 1 period, which still needs to move ~10 radians so 10rad/1wlDistribution"
      ],
      "metadata": {
        "id": "I6CnnNg-IMkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkir5IJ5TWIT"
      },
      "outputs": [],
      "source": [
        "# Generate the 39x2 plots, like above, with a gapless checkerboard\n",
        "WLC_num = 39\n",
        "PCA_1, PCA_2 = 1, 1\n",
        "x_squares, y_squares, center_square, location, location_demo = 5, 5, [3, 3], (44, 88), (44, 125)\n",
        "fig, axs = plt.subplots(nrows=2, ncols=WLC_num, figsize=(8*WLC_num, 14))# sharey=False)\n",
        "for i in range(WLC_num):\n",
        "    x, y = image_data_FPI[0][0][0], image_data_FPI[0][0][1]\n",
        "    if len(np.shape(image_data_FPI)) == 5:\n",
        "        signalMatrix_FPI = set_signalMatrix_1_WLC_2_PCA(image_data_FPI, x, y, PCA_1, PCA_2, i)   #elif len(np.shape(image_data_FPI)) == 4:   #signalMatrix_FPI = set_signalMatrix_1_WLC_1_PCA(image_data_FPI, x, y, 2, 32)\n",
        "    else:\n",
        "        print('Error... image_data_FPI != 5\\n') #4 or\n",
        "    Ydelay = (i * -0.26) + 2.4 # The black starts at the top, goes to the bottom and back to the top (1 cycle), and then to the bottom again (maybe a little more), so about 1.5 cycles, or 1.6-1.7... That would be 2*pi*1.6 = 10 radians over 39 WLC = 0.26rad/WLC...\n",
        "    Ydelay2= (i * -0.26) + 2.4 # this moves the CB's black (wave) down. The observation's black kinda moves down (or the white up)\n",
        "    Xdelay = diameter / 4\n",
        "    wlD = wlDistribution[i]\n",
        "    max_brightness, amp_radial_boost, amp_nonRad_less, decay_factor = 30, 1, 2, 0.4 # MB=24,18,10 --> too bright\n",
        "    checkerboard_demo, CB4D_D = make_oscillating_checkerboard_noGap(diameter, x_squares, y_squares, center_square, max_brightness, amp_nonRad_less, location_demo, Xdelay, wlD, decay_factor) # Ydelay2,\n",
        "    #checkerboard_Ydelay, CB4D_Ydelay = make_oscillating_checkerboard_noGap(diameter, x_squares, y_squares, center_square, max_brightness, amp_nonRad_less, location, Xdelay, Ydelay, decay_factor)\n",
        "    checkerboard, CB4D = make_oscillating_checkerboard_noGap(diameter, x_squares, y_squares, center_square, max_brightness, amp_nonRad_less, location, Xdelay, wlD, decay_factor) # Ydelay,\n",
        "    mitigated_signal_D = add_wavy_checkerboard(signalMatrix_FPI, checkerboard_demo)\n",
        "    #mitigated_signal_Ydelay = add_wavy_checkerboard(signalMatrix_FPI, checkerboard_Ydelay)\n",
        "    mitigated_signal = add_wavy_checkerboard(signalMatrix_FPI, checkerboard)\n",
        "    axs[0, i].imshow(mitigated_signal_D, origin='lower', cmap='Blues_r') # im_side[2i] =\n",
        "    axs[0, i].plot(possible_FPI_pixel[0], possible_FPI_pixel[1], marker='o', color='red')\n",
        "    axs[1, i].imshow(mitigated_signal, origin='lower', cmap='Blues_r') # im_side[2i+1] =\n",
        "    axs[1, i].title.set_text(str(i+1)+\". min: \"+str(np.round(np.min(mitigated_signal), 2)) +\". max: \"+str(np.round(np.max(mitigated_signal), 2)) )\n",
        "    #axs[2, i].imshow(mitigated_signal_Ydelay, origin='lower', cmap='Blues_r') # im_side[2i+1] =\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the contents of the modifications in the postproc.py file, which is used to apply the CB to each exposure before de-rotating and stacking:\n",
        "\n",
        "#...after the elif processing_type == 'CODI': section:\n",
        "\n",
        "\n",
        "### ### ### Make plots of original res_raw images (WLC = 8, for 32 exposures), and mitigated images ### ### ###\n",
        "\n",
        "    # Define variables: An original res_raw that preserves the values passed before my edits, and a new matrix for testing (negatives)\n",
        "    # It seems that the simpler y = x, without np.multiply leads to some weird equivalences and doesn't generate clean new variables\n",
        "    res_raw_original = np.multiply(res_raw, 1)\n",
        "    res_raw_neg = np.multiply(res_raw, -1)  # THIS IS IMPORTANT... AFFECTS FINAL OUTCOME, WHICH IT SHOULDN'T - 10 SEP 2023\n",
        "\n",
        "    shapeResRaw, shapeResRot = np.shape(res_raw), np.shape(res_rot)\n",
        "    print(\"\\n\\n\\tbefore modification, np.shape(res_raw):\", shapeResRaw)\n",
        "    print(\"\\n\\tbefore modification, np.shape(res_rot):\", shapeResRot)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    diameter = 5;                    D = diameter\n",
        "    radius = int(diameter/2);        R = radius\n",
        "    separation = 50;                 S = separation\n",
        "    decay_factor = 0.9;              DF= decay_factor\n",
        "    angular_squares, radial_squares = 4, 4 # I think there's no code that uses this now - 5 July 23\n",
        "    max_brightness, MB = 10, 10   # half_edge = np.sqrt(radius**2 + separation**2) - separation + radius\n",
        "    amp_nonRad_less = 2\n",
        "    x_squares, y_squares, center_square, location, location_demo = 5, 5, [3, 3], (44, 88), (44, 125)\n",
        "    max_brightness, amp_radial_boost, amp_nonRad_less, decay_factor = 30, 1, 2, 0.4 # MB=24,18,10 --> too bright\n",
        "    wavelength_channels = [ 954.32282227,  962.62163342,  971.8455533, 981.89907773,  991.62082995, 1001.70638262,\n",
        "                        1012.66201578, 1023.29215927, 1033.63748036, 1043.90899136, 1054.17332605, 1064.93904728,\n",
        "                        1075.51906673, 1085.48399237, 1095.372864, 1105.07626751, 1115.18984928, 1127.09242581,\n",
        "                        1138.79673007, 1149.43864103, 1159.42615783, 1169.31067405, 1179.38222723, 1189.4464981,\n",
        "                        1199.5333784, 1209.88668205, 1220.04015567, 1229.96503806, 1240.57338913, 1250.6362063,\n",
        "                        1260.9653672,  1271.4195118,  1281.94965148,1291.7051642,  1300.62445043, 1309.61923874,\n",
        "                        1318.81874937, 1327.10100597, 1333.64664519 ]\n",
        "    angles_BPic20 = [-17.10792503, -18.04861444, -19.00754622, -19.94279229, -20.87967121, -21.83354603, -22.80021385,\n",
        "                -23.7361827,  -24.67226941, -25.64268633, -26.66322205, -27.64449798, -28.60997872, -29.57157742,\n",
        "                -30.54446954, -31.52492384, -32.49536969, -33.46763605, -34.46496023, -35.42006557, -36.40736831,\n",
        "                -37.39081194, -38.40896634, -39.38236154, -40.37439087, -41.34595291, -42.32240888, -43.28713799,\n",
        "                -44.25890071, -45.2366961, -46.19115248, -47.14049291]\n",
        "    # Given a range (1.5*pi radians), make a discrete sign function that is evaluated in the spacing that the wavelength channels are distributed\n",
        "    wlMin, wlMax, wlDistribution, wlDistrib_sin = np.min(wavelength_channels), np.max(wavelength_channels), [], []\n",
        "    WLC_num = 39\n",
        "    x_squares, y_squares, center_square, location, location_demo, Xdelay = 5, 5, [3, 3], (44, 88), (44, 125), diameter / 4\n",
        "    working_count = 0\n",
        "    #fig, axs = plt.subplots(nrows=2, ncols=WLC_num, figsize=(8*WLC_num, 14))# sharey=False)\n",
        "    for i in range(WLC_num):\n",
        "        wlDistribution.append(10*(wlMax - wavelength_channels[i])/(wlMax - wlMin) - 7.6) # This will replace 39 WLCs with 1 period, which still needs to move ~10 radians so 10rad/1wlDistribution\n",
        "        wlDistrib_sin.append(np.sin(wlDistribution[i]))\n",
        "        wlD = wlDistribution[i]\n",
        "        #checkerboard_demo, CB4D_D = make_oscillating_checkerboard_noGap(diameter, x_squares, y_squares, center_square, max_brightness, amp_nonRad_less, location_demo, Xdelay, wlD, decay_factor) # Ydelay2,\n",
        "        #checkerboard_Ydelay, CB4D_Ydelay = make_oscillating_checkerboard_noGap(diameter, x_squares, y_squares, center_square, max_brightness, amp_nonRad_less, location, Xdelay, Ydelay, decay_factor)\n",
        "        checkerboard, CB4D = make_oscillating_checkerboard_noGap(diameter, x_squares, y_squares, center_square, max_brightness, amp_nonRad_less, location, Xdelay, wlD, decay_factor) # Ydelay,\n",
        "        #mitigated_signal_D = add_wavy_checkerboard(signalMatrix_FPI, checkerboard_demo)\n",
        "        #mitigated_signal_Ydelay = add_wavy_checkerboard(signalMatrix_FPI, checkerboard_Ydelay)\n",
        "\n",
        "        ### ### Align the CB, and then add it to the res_raw\n",
        "        #print(np.shape(res_raw))  # (39, 32, 200, 200)!\n",
        "        for j in range(len(angles_BPic20)):\n",
        "            #print(\"\\nj:\"+str(j)+\". -(j+1):\"+str(-(j+1))+\"\\nangles_BPic20[j]:\"+str(angles_BPic20[j])+\"\\nangles_BPic20[-j]\"+str(angles_BPic20[-(j+1)]))\n",
        "            #print(\"-1*angles_BPic20[j] should start with: -17.1, and is: \"+str(-1*angles_BPic20[j]))     # yes... the angles are going in reverse order...\n",
        "            #print(\"-1*angles_BPic20[-(j+1)] start with: -47.1, and is: \"+str(-1*angles_BPic20[-(j+1)]))\n",
        "            # Test: instead of angles = 60 and -60, try 60 and 300 or something positive... 10 Sep 2023\n",
        "            aligned_CB, rotMat = align_CB_to_angle(checkerboard, -1*angles_BPic20[j])                   # a small-ish 50,50 matrix\n",
        "            aligned_CB_neg, rotMat_neg = align_CB_to_angle(checkerboard, -1*angles_BPic20[-(j+1)])      # a small-ish 50,50 matrix\n",
        "\n",
        "            '''     THESE WORKED! Separated by a set 120 degree difference\n",
        "            print(np.shape(aligned_CB))\n",
        "            print(np.shape(aligned_CB_neg))\n",
        "            fig, axs = plt.subplots(nrows=1, ncols=2)#, figsize=(32*6, 32*0.625))\n",
        "            axs[0].title.set_text('Testing the alignment of CBs in plots, j (exposure) is: '+str(j))\n",
        "            axs[0].imshow(aligned_CB, origin='lower', cmap='Blues_r')\n",
        "            axs[1].imshow(aligned_CB_neg, origin='lower', cmap='Blues_r')\n",
        "            plt.show()\n",
        "            '''\n",
        "\n",
        "            #mitigated_signal = add_wavy_checkerboard(res_raw[i,j,:,:], aligned_CB)          # a 200,200 image\n",
        "            #mitigated_signal_neg = add_wavy_checkerboard(res_raw[i,j,:,:], aligned_CB_neg)  # a 200,200 image\n",
        "            mitigated_signal = add_wavy_checkerboard(np.zeros((200,200)), aligned_CB)          # The CB on a blank background\n",
        "            mitigated_signal_neg = add_wavy_checkerboard(np.zeros((200,200)), aligned_CB_neg)  # The negative CB on a blank\n",
        "\n",
        "            '''     THESE WORKED! Separated by an 120 degree input\n",
        "            print(np.shape(mitigated_signal))\n",
        "            print(np.shape(mitigated_signal_neg))\n",
        "            fig, axs = plt.subplots(nrows=1, ncols=2)#, figsize=(32*6, 32*0.625))\n",
        "            axs[0].title.set_text('Testing the mitigated signals in plots, j (exposure) is: '+str(j+1))\n",
        "            axs[0].imshow(mitigated_signal, origin='lower', cmap='Blues_r')\n",
        "            axs[1].imshow(mitigated_signal_neg, origin='lower', cmap='Blues_r')\n",
        "            plt.show()\n",
        "            '''\n",
        "\n",
        "            '''     print shape of res raw,,, should be 200x200...?  ##### NEXT STEP HERE 8 SEP 2023!!! ###\n",
        "            print('shape of res_raw[ij]', np.shape(res_raw[i,j,:,:]))           # 200x200\n",
        "            print('shape of res_raw_neg[ij]', np.shape(res_raw_neg[i,j,:,:]))   # 200x200\n",
        "            print('shape of mit_sig', np.shape(mitigated_signal))               # 200x200\n",
        "            print('shape of mit_sig_neg', np.shape(mitigated_signal_neg))       # 200x200\n",
        "            '''\n",
        "\n",
        "\n",
        "            # Before: Print res_raw[i,j,:,:], mitigated_signal, res_raw_neg[i,j,:,:], and mitigated_signal_neg\n",
        "            if j % 8 == 0 and i % 8 == 0:\n",
        "                print('\\n\\n\\tFIRST...\\nres_raw[i,j,73:84,57:69]', res_raw[i,j,76:82,58:68])\n",
        "                print('mitigated_signal[73:84,57:69]', mitigated_signal[76:82,58:68])\n",
        "                print('res_raw_neg[i,j,73:84,57:69]', res_raw_neg[i,j,76:82,58:68])\n",
        "                print('mitigated_signal_neg[73:84,57:69]', mitigated_signal_neg[76:82,58:68])\n",
        "\n",
        "            # Assign values in the res_raw matrix\n",
        "            res_raw[i,j,:,:] = mitigated_signal\n",
        "            res_raw_neg[i,j,:,:] = mitigated_signal_neg # Check around here for errors! 8 Sep\n",
        "\n",
        "            # After: Print res_raw[i,j,:,:], mitigated_signal, res_raw_neg[i,j,:,:], and mitigated_signal_neg\n",
        "\n",
        "\n",
        "            counter_mitSig = 0\n",
        "            counter = 0\n",
        "\n",
        "            if j % 8 == 0 and i % 8 == 0:\n",
        "                print('Check the values of the reduction at this WLC and exposure, i, j =', i, j)\n",
        "                if len(mitigated_signal) != len(mitigated_signal_neg):\n",
        "                    print('The matrices are different length... This is a problem to fix! (should I use shape instead?)')\n",
        "                    counter_mitSig = 1\n",
        "                for k in range(200):\n",
        "                    for l in range(200):\n",
        "                        #if res_raw[i,j,k,l] != res_raw_neg[i,j,k,l]:\n",
        "                        if mitigated_signal[k,l] != mitigated_signal_neg[k,l]:\n",
        "                            counter_mitSig = 1\n",
        "                if counter_mitSig == 1:\n",
        "                    print('mitSig & its negative are different (this is GOOD)')\n",
        "                else:\n",
        "                    print('mitSig & its negative are the same, which is BAD!')\n",
        "\n",
        "                if len(res_raw[i,j,:,:]) != len(res_raw_neg[i,j,:,:]):\n",
        "                    print('The matrices are different length... This is a problem to fix! (should I use shape instead?)')\n",
        "                    counter = 1\n",
        "                for k in range(200):\n",
        "                    for l in range(200):\n",
        "                        if res_raw[i,j,k,l] != res_raw_neg[i,j,k,l]:\n",
        "                            counter = 1\n",
        "                        if res_raw[i,j,k,l] > 16: # >8 yields ~12 points... >16 yields 5 points\n",
        "                            print('High signal strength (>16) at coordinates k, l =', k, l)\n",
        "                if counter == 1:\n",
        "                    print('resRaw & its negative are different (this is GOOD)')\n",
        "                else:\n",
        "                    print('resRaw & its negative are the same, which is BAD!')\n",
        "            #working_count += 1\n",
        "            #print(\"it's working, res_raw & res_raw_neg are different...\")\n",
        "        #print('\\n\\tThe working_count (number of differences between regular and negative rotation) is:', working_count)\n",
        "        #equal_matrix_test(res_raw, res_raw_neg)\n",
        "\n",
        "        '''mitigated_signal_unaligned = add_wavy_checkerboard(res_raw[i,:,:,:], checkerboard)\n",
        "        for j in range(len(angles)):\n",
        "            mitigated_signal = align_CB_to_angle(mitigated_signal_unaligned[j,:,:], angles[j]) #maybe -j\n",
        "            mitigated_signal_backwards = align_CB_to_angle(mitigated_signal_unaligned[j,:,:], angles[-j])\n",
        "            #should edit the last two dimensions so that they are printing coordinate vales in the region the CB has been applied\n",
        "            #print('\\ni = '+str(i)+'. Before the res_raw[i,8,99:101,99:101] =\\n'+str(res_raw[i,8,99:101,99:101])+'.')\n",
        "            res_raw[i,j,:,:] = mitigated_signal\n",
        "            res_raw_backwards[i,j,:,:] = mitigated_signal_backwards\n",
        "            #print('Now the res_raw[i,8,99:101,99:101] =\\n'+str(res_raw[i,8,99:101,99:101])+'.')\n",
        "        '''\n",
        "\n",
        "        # Make 2 subplots... 1 is of res_raw, 1x4 of WLC=8, and exposures={4, 12, 20, 28}. 2 is of the mitigated\n",
        "\n",
        "    # outside the for loop, plot the two subplots\n",
        "    '''fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(36, 18))\n",
        "    axs[0].imshow(res_raw[8, 4,:,:], origin='lower', cmap='Blues_r')\n",
        "    axs[1].imshow(res_raw[8,12,:,:], origin='lower', cmap='Blues_r')\n",
        "    axs[2].imshow(res_raw[8,20,:,:], origin='lower', cmap='Blues_r')\n",
        "    axs[3].imshow(res_raw[8,28,:,:], origin='lower', cmap='Blues_r')\n",
        "    plt.show()\n",
        "    '''\n",
        "\n",
        "    print('\\tFinished running the \\'for i in range(WLC_num):\\' for loop!')\n",
        "\n",
        "    print(\"\\n\\n\\tbefore modification, np.shape(res_raw):\", shapeResRaw)\n",
        "    print(\"\\n\\tbefore modification, np.shape(res_rot):\", shapeResRot)\n",
        "    print(\"\\n\\n\\tafter modification, np.shape(res_raw):\", np.shape(res_raw))\n",
        "    print(\"\\n\\tafter modification, np.shape(res_rot):\", np.shape(res_rot))\n",
        "\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=3, ncols=32, figsize=(32*6, 32*0.625))\n",
        "    for i in range(32): # range(len(res_raw_original[0,:,0,0]))\n",
        "        axs[0, i].title.set_text(\"exposure #\"+str(i+1))#+\". min: \"+str(np.round(np.min(mitigated_signal), 2)) +\". max: \"+str(np.round(np.max(mitigated_signal), 2)) )\n",
        "        axs[0, i].imshow(res_raw_original[11, i,:,:], origin='lower', cmap='Blues_r')\n",
        "        axs[1, i].imshow(res_raw[11, i,:,:], origin='lower', cmap='Blues_r')\n",
        "        axs[2, i].imshow(res_raw_neg[11, i,:,:], origin='lower', cmap='Blues_r')\n",
        "\n",
        "    #fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(36, 18))\n",
        "    #axs[0].imshow(res_raw[8, 4,:,:], origin='lower', cmap='Blues_r')\n",
        "    #axs[1].imshow(res_raw[8,12,:,:], origin='lower', cmap='Blues_r')\n",
        "    #axs[2].imshow(res_raw[8,20,:,:], origin='lower', cmap='Blues_r')\n",
        "    #axs[3].imshow(res_raw[8,28,:,:], origin='lower', cmap='Blues_r')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    ''' current thought, or state of the problem\n",
        "    I have modified the raw images,\n",
        "    I don't think the program has any code to then de-rotate and stack these modified images.\n",
        "    That is, the rest of the reduction is using\n",
        "    the res_rot that it calculated at the end of the original postproc.py file/code and\n",
        "    doesn't recalculate the res_rot from the new res_raw I made by\n",
        "    modifying the code after the end of the new postproc.py file/code. Is this the issue? I '''\n",
        "\n",
        "\n",
        "\n",
        "    ''' CODE APPENDIX (future trash)\n",
        "\n",
        "    if rotMat.all() == rotMat_neg.all():\n",
        "                print('The rotation matrices are not working... The positive & negative are the same')\n",
        "            if aligned_CB.all() != aligned_CB_neg.all():\n",
        "                print('It is working... the positive and negative angle alignments make different CB')\n",
        "    '''\n",
        "\n",
        "\n",
        "    return res_raw, res_rot\n"
      ],
      "metadata": {
        "id": "Yl2HDDRT1l6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMLhMLjCTYJd"
      },
      "outputs": [],
      "source": [
        "''' THE CODE APPENDIX\n",
        "\n",
        "20 Aug 2023: Use this code/mitigation technique in/for/with the postproc.py file, use Jupyter.\n",
        "\n",
        "# compare the Ydelays of the original and with the new wlDistribution, now they are close... 2.4 & 2.4 to -7.5 and -7.6\n",
        "WLC_num = 39\n",
        "PCA_1, PCA_2 = 1, 1\n",
        "x_squares, y_squares, center_square, location, location_demo = 5, 5, [3, 3], (44, 88), (44, 125)\n",
        "fig, axs = plt.subplots(nrows=2, ncols=WLC_num, figsize=(8*WLC_num, 14))# sharey=False)\n",
        "Ydelay_old = []\n",
        "Ydelay_new = []\n",
        "for i in range(WLC_num):\n",
        "    x, y = image_data_FPI[0][0][0], image_data_FPI[0][0][1]\n",
        "    if len(np.shape(image_data_FPI)) == 5:\n",
        "        signalMatrix_FPI = set_signalMatrix_1_WLC_2_PCA(image_data_FPI, x, y, PCA_1, PCA_2, i)   #elif len(np.shape(image_data_FPI)) == 4:   #signalMatrix_FPI = set_signalMatrix_1_WLC_1_PCA(image_data_FPI, x, y, 2, 32)\n",
        "    else:\n",
        "        print('Error... image_data_FPI != 5\\n') #4 or\n",
        "    Ydelay = (i * -0.26) + 2.4 # The black starts at the top, goes to the bottom and back to the top (1 cycle), and then to the bottom again (maybe a little more), so about 1.5 cycles, or 1.6-1.7... That would be 2*pi*1.6 = 10 radians over 39 WLC = 0.26rad/WLC...\n",
        "    Ydelay2= (i * -0.26) + 2.4 # this moves the CB's black (wave) down. The observation's black kinda moves down (or the white up)\n",
        "    Xdelay = diameter / 4\n",
        "    Ydelay_old.append(Ydelay)\n",
        "    Ydelay_new.append(wlDistribution[i])\n",
        "print(\"Ydelay_old\", Ydelay_old)\n",
        "print(\"Ydelay_new\", Ydelay_new)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzalbGOtcP4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIgCzCVM0y1N0di2rGA5td"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}